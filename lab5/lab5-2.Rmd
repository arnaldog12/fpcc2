---
title: "Lab 5 - Checkpoint 2"
author: "Arnaldo Gualberto"
date: "25/06/2017"
output: 
  html_document:
    smart: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

O objetivo checkpoint 2 do Lab 5 é avaliar se a aparência física (beleza) de um professor influência significativamente na avaliação docente dos professores pelos alunos. Além disso, vamos também analisar se outras variáveis influenciaram na nota da avalização, são elas:

* __nível do professor (_rank_)__: horista (_teaching_), assistente (_tenure track_) ou titular (_tenured_)
* __etnia (_ethnicity_)__: não minoria ou minoria
* __gênero (_gender_)__: feminino ou masculino
* __linguagem (_language_)__: inglês ou não inglês 
* __idade (_age_)__: idade do professor
* __porcentagem de alunos na turma que concluíram a avaliação (_cls_perc_eval_)__
* __número de alunos na turma que concluíram a avaliação (_cls_did_level_)__
* __número total de alunos na turma (_cls_students_)__
* __nível da disciplina (_cls_level_)__: introdutória ou avançada
* __número de professores ministrando módulos na disciplina dentro da amostra (_cls_profs_)__: único ou múltiplos
* __número de créditos na disciplina (_cls_credits_)__: um crédito ou múltiplos créditos
* __roupa do professor na foto avaliada (_pic_outfit_)__: informal ou formal
* __cor da foto avaliada (_pic_color_)__: colorida ou preto e branco

queremos avaliar se a beleza possui um efeito significativo no score dos professores, levando em conta os demais fatores que foram identificados como tento possíveis efeitos, que são as variáveis rank, ethnicity, gender, language, age, cls_*, pic_outfit e pic_color

# 0. Imports and Settings

```{r, message=FALSE}
library(broom)
library(car)
library(dplyr, warn.conflicts = FALSE)
library(ggfortify)
library(GGally, warn.conflicts = FALSE)
library(ggplot2)
library(modelr, warn.conflicts = FALSE)
library(readr)
library(simpleboot)

source('multiplot.R')

# Coloca todos os titulos dos gráficos centralizados
theme_update(plot.title = element_text(hjust=0.5))
```

# 1. Importação dos Dados

```{r}
dados <- read_csv("data/evals.csv")
```

Além das colunas citadas anteriormente, também podemos ver outras colunas. A coluna _score_ representa a média da avaliação do docente e é essa variável que tentaremos predizer. As colunas _bty\_\*_ representam a avaliação da beleza do professor feita por seis alunos de diferentes sexos e períodos (iniciante e avançado).

# 2. Análise Descritiva

```{r}
dados %>% summary()
```

```{r, fig.width=12}
p1 <- dados %>%
  ggplot(aes(x = score)) +
  geom_bar() +
  xlim(c(1,9))

p2 <- dados %>%
  ggplot(aes(x = bty_avg)) +
  geom_bar() +
  xlim(c(1,9))

multiplot(p1, p2)
```

Dos 463 professores, apenas pouco mais de 10 receberam nota máxima na avaliação.

```{r}
ggplot() +
  geom_boxplot(data = dados, aes(x = 0, y = score)) +
  geom_point(data = dados, aes(x = 0, y = score), position = position_jitter(width = 0.2), alpha = 0.5) +
  geom_boxplot(data = dados, aes(x = 1, y = bty_avg)) +
  geom_point(data = dados, aes(x = 1, y = bty_avg), position = position_jitter(width = 0.2), alpha = 0.5)
```

```{r}
dados %>%
  ggplot(aes(x = bty_avg, y = score)) +
  geom_point(alpha = 0.5)
```

# 3. Regressão Linear

### 3.1 Regressão linear simples
```{r}
mod <- lm(data = dados, score ~ bty_avg)

summary(mod)
tidy(mod, conf.int = TRUE)
glance(mod, conf.int = TRUE)

dados %>%
  add_predictions(mod) %>%
  ggplot(aes(x = bty_avg, y = score)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(y = pred), colour = "red")
```

```{r}
cor(dados$score, dados$bty_avg, method = "pearson")
```

Falar sobre o coeficiente de correlação, a não-presença de outliers, não-linearidade (presente, mas não forte)

```{r}
predictions <- predict(mod, dados, interval = "predict") %>% as.data.frame()

dados %>%
  add_predictions(mod) %>%
  ggplot(aes(x = bty_avg, y = score)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(y = pred), colour = "red") +
  geom_line(aes(x = bty_avg, y = predictions$lwr), colour = "blue") +
  geom_line(aes(x = bty_avg, y = predictions$upr), colour = "blue")
```


```{r}
dados %>%
  add_residuals(mod) %>%
  ggplot(aes(x = bty_avg, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, colour = "blue")
```

```{r}
set.seed(42)

mod.boot <- lm.boot(mod, R = 5000)
summary(mod.boot)
```

```{r}
perc(mod.boot, p = c(0.025, 0.975))
```

```{r}
confint(mod)
```

```{r}
# http://rpubs.com/sinhrks/plot_lm 
autoplot(mod) + theme_bw()
```

__No plot de studentized residuals, pontos com resíduos normalizados maiores que 3 são suspeitos. Para leverage, o adequado é olhar pontos com leverage muito acima dos demais, ou maior que (p + 1)/n. (p sendo o número de preditores.)__

De acordo com as análises efetuadas, podemos concluir que __há uma relação linear estatística significativa entre a avaliação do professor e sua beleza__ - uma vez que o intervalo de confiança do slope (*bty_avg*) não intercepta o valor zero e seu $p\mbox{-}value < 0.05$. Além disso, __também não há sinais no gráfico de resíduos que demonstrem que não há um efeito entre o score e a média da beleza de um professor__. Isto é, os resíduos não são muito distantes de zero, não dão sinal de linearidade, e se comportam uniformemente durante o gráfico. __No entanto, como ambos $R^2$ e $R^2-adjusted$ foram baixos (0.03502226 e 0.03292903, respectivamente), a relação linear entre a beleza e o score é muito fraca__. Aproximadamente, __apenas 3,5% da variância na avaliação do professor é explicada pela média da avaliação da beleza__.

### 3.2 Regressão Linear Múltipla

Antes de ajustar o modelo da regressão para múltiplas variáveis, eu acredito que algumas variáveis serão mais importantes que outras, são elas: 

* _rank_: de certa forma, professores mais experientes tem melhor didática
* _cls\_level_: acredito que disciplinas introdutórias são mais fáceis de ministrar (pelo professor) e compreender (pelo aluno). Logo, os alunos devem tender a dar notas mais altas aos professores das disciplinas que eles aprendem mais fácil.

```{r}
multi <- lm(data = dados, score ~ . )

summary(multi)
tidy(multi, conf.int = TRUE)
glance(multi, conf.int = TRUE)
```

```{r}
vif(multi)
```

colinearidade: Recomendação: VIF < 5 ou VIF < 10



TODO: 
- mostrar os resíduos para diferentes variáveis de entrada

# 4. Conclusões

