---
title: "Lab 5 - Checkpoint 2"
author: "Arnaldo Gualberto"
date: "25/06/2017"
output: 
  html_document:
    smart: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

O objetivo checkpoint 2 do Lab 5 é avaliar se a aparência física (beleza) de um professor influência significativamente na avaliação docente dos professores pelos alunos. Além disso, vamos também analisar se outras variáveis influenciaram na nota da avalização, são elas:

* __nível do professor (_rank_)__: horista (_teaching_), assistente (_tenure track_) ou titular (_tenured_)
* __etnia (_ethnicity_)__: não minoria ou minoria
* __gênero (_gender_)__: feminino ou masculino
* __linguagem (_language_)__: inglês ou não inglês 
* __idade (_age_)__: idade do professor
* __porcentagem de alunos na turma que concluíram a avaliação (_cls_perc_eval_)__
* __número de alunos na turma que concluíram a avaliação (_cls_did_level_)__
* __número total de alunos na turma (_cls_students_)__
* __nível da disciplina (_cls_level_)__: introdutória ou avançada
* __número de professores ministrando módulos na disciplina dentro da amostra (_cls_profs_)__: único ou múltiplos
* __número de créditos na disciplina (_cls_credits_)__: um crédito ou múltiplos créditos
* __roupa do professor na foto avaliada (_pic_outfit_)__: informal ou formal
* __cor da foto avaliada (_pic_color_)__: colorida ou preto e branco

# 0. Imports and Settings

```{r, message=FALSE}
library(broom)
library(car)
library(dplyr, warn.conflicts = FALSE)
library(ggfortify)
library(GGally, warn.conflicts = FALSE)
library(ggplot2)
library(knitr)
library(modelr, warn.conflicts = FALSE)
library(readr)
library(simpleboot)

source('multiplot.R')

# Coloca todos os titulos dos gráficos centralizados
theme_update(plot.title = element_text(hjust=0.5))
```

# 1. Importação dos Dados

```{r}
dados <- read_csv("data/evals.csv")
```

Além das colunas citadas anteriormente, também podemos ver outras colunas. A coluna _score_ representa a média da avaliação do docente e é essa variável que tentaremos predizer. As colunas _bty\_\*_ representam a avaliação da beleza do professor feita por seis alunos de diferentes sexos e períodos (iniciante e avançado).

# 2. Análise Descritiva

Vamos começar nossa análise descritiva pelo sumário dos dados:

```{r}
dados %>% summary() %>% kable()
```

O sumário dos dados nos mostra que:

* Ao todo, temos 463 professores avaliados e 21 variáveis, sendo 12 númericas e 9 categóricas;
* Na média e na mediana, os professores tem boas avaliações em geral (> 4.0);
* Uma porcentagem razoável de estudantes respondia as pesquisas (aproximadamente 75%), sendo mais de 36 estudantes na média;
* A média e mediana das avaliações da beleza foi bem baixa na minha opinião entre os estudantes de todos os níveis e na avaliação média.

Agora, vamos analisar a distribuição de cada uma das variáveis. Vou começar pelas variáveis numéricas:

```{r, fig.width=12, fig.height=8}
barPlot <- function(data, x)
{
  plot <- data %>%
    ggplot(aes_string(x = x)) +
    geom_bar()
  return(plot)
}

p1 <- barPlot(dados, "score")
p2 <- barPlot(dados, "bty_avg")
p3 <- barPlot(dados, "age")
p4 <- barPlot(dados, "cls_perc_eval")
p5 <- barPlot(dados, "cls_did_eval")
p6 <- barPlot(dados, "cls_students")

multiplot(p1, p2, p3, p4, p5, p6, cols = 1)
```

Podemos observar que as variáveis *cls_did_eval* e *cls_students* apresentam uma distribuição concentrada à esquerda com cauda longa à direita, enquanto o *score* tem uma distribuição oposta. Além disso, *bty_avg* e *age* apresentam distribuições multimodais.

Vamos ver como se comportam as variáveis categóricas:

```{r, fig.width=12}
p1 <- barPlot(dados, "rank")
p2 <- barPlot(dados, "ethnicity")
p3 <- barPlot(dados, "gender")
p4 <- barPlot(dados, "language")
p5 <- barPlot(dados, "cls_level")
p6 <- barPlot(dados, "cls_profs")
p7 <- barPlot(dados, "cls_credits")
p8 <- barPlot(dados, "pic_outfit")
p9 <- barPlot(dados, "pic_color")

multiplot(p1, p2, p3, p4, p5, p6, p7, p8, p9, cols = 3)
```

Os gráficos acima nos mostram o desbalanceamento dos dados, em especial sobre as variáveis *language*, *cls_credit*, *ethnicity*, *pic_outfit*, e *pic_color*, que estão presentes em menos de 100 vezes nos dados.

Vamos agora analisar a dispersão das variáveis em relação ao score. Novamente, vou separar essa análise para as variáveis númericas e categóricas. No caso das variáveis númericas, também calcularei o coeficiente de correlação.

```{r, fig.width=12}
pointPlot <- function(data, x, y)
{
  plot <- data %>%
    ggplot(aes_string(x = x, y = y)) +
    geom_point(alpha = 0.3) +
    ylim(c(1,5))
  return(plot)
}

p1 <- pointPlot(dados, "age", "score")
p2 <- pointPlot(dados, "cls_perc_eval", "score")
p3 <- pointPlot(dados, "cls_did_eval", "score")
p4 <- pointPlot(dados, "cls_students", "score")
p5 <- pointPlot(dados,"bty_f1lower", "score")

multiplot(p1, p2, p3, p4, cols = 2)

cor(dados$age, dados$score)
cor(dados$cls_perc_eval, dados$score)
cor(dados$cls_did_eval, dados$score)
cor(dados$cls_students, dados$score)
```

É possível observar que não há uma linearidade aparente entre as variáveis mostradas e o _score_. Além disso, o maior coeficiente de correlação (0.18) ocorreu para a variável *cls_perc_eval*. Mesmo assim, esse valor representa uma correlação positiva, porém fraca.

```{r, fig.width=12}
p1 <- pointPlot(dados, "rank", "score")
p2 <- pointPlot(dados, "ethnicity", "score")
p3 <- pointPlot(dados, "gender", "score")
p4 <- pointPlot(dados, "language", "score")
p5 <- pointPlot(dados, "cls_level", "score")
p6 <- pointPlot(dados, "cls_profs", "score")
p7 <- pointPlot(dados, "cls_credits", "score")
p8 <- pointPlot(dados, "pic_outfit", "score")
p9 <- pointPlot(dados, "pic_color", "score")

multiplot(p1, p2, p3, p4, p5, p6, p7, p8, p9, cols = 3)
```

A relação entre as variáveis categóricas e o score não nos diz muita coisa, já que a faixa de scores é basicamente a mesma para todas as variáveis. Porém, um fato interessante que pode ser observado é a tendência de scores mais altos para disciplinas de um crédito.

Por fim, vamos terminar nossa análise descritiva observando a (cor)relação entre as variáveis de interesse para a regressão linear simples: *bty_avg* e _score_:

```{r, fig.align="center"}
dados %>%
  ggplot(aes(x = bty_avg, y = score)) +
  geom_point(alpha = 0.5) +
  ggtitle("Scatterplot do score pela média da beleza (bty_avg)")

cor(dados$score, dados$bty_avg, method = "pearson")
```

Pelo gráfico acima, já podemos avaliar algumas das condições para regressão linear:

* __Linearidade__: o coeficiente de correlação nos mostra que __há pouca linearidade entre o _score_ do professor e a média da avaliação da beleza do professor. Logo, essa condição já está violada.__
* __Outliers__: por outro lado, não há nenhum ponto amplamente afastado dos demais, representando um outlier.  

# 3. Regressão Linear

### 3.1 Regressão linear simples

Vamos começar criando o modelo linear simples para tentar predizer o score da avaliação do professor pela média da beleza:

```{r, fig.align="center"}
mod <- lm(data = dados, score ~ bty_avg)

summary(mod)
tidy(mod, conf.int = TRUE) %>% kable()
glance(mod, conf.int = TRUE) %>% kable()

predictions <- predict(mod, dados, interval = "predict") %>% as.data.frame()

dados %>%
  add_predictions(mod) %>%
  ggplot(aes(x = bty_avg, y = score)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(y = pred), colour = "red") +
  geom_line(aes(y = predictions$lwr), colour = "blue") +
  geom_line(aes(y = predictions$upr), colour = "blue") +
  ggtitle("Regressão Linear do score por bty_avg")
```

O gráfico e os dados acima já nos mostram informações interessantes:

* A equação da nossa reta é dada por: 

$$score = 3.88 + 0.06 \cdot bty\_avg$$

Isso significa que __para cada unidade que aumentamos *bty_avg*, o _score_ do professor aumenta apenas 0.06__.

* __Há uma relação linear estatísticamente significativa entre a avaliação do professor e sua beleza__, uma vez que o intervalo de confiança do slope (*bty_avg*) não intercepta o valor zero e seu $p\mbox{-}value < 0.05$

* __Porém, como ambos $R^2$ e $R^2\mbox{-}adjusted$ foram baixos (0.03502226 e 0.03292903, respectivamente), a relação linear entre a beleza e o score é muito fraca__ (como confirmado pelo coeficiente de correlação). Aproximadamente, __apenas 3,5% da variância na avaliação do professor é explicada pela média da avaliação da beleza__.

Temos agora que analisar o gráfico de resíduos e seu histograma para verificarmos as demais condições:

```{r, fig.align="center"}
dados %>%
  add_residuals(mod) %>%
  ggplot(aes(x = bty_avg, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, colour = "blue") +
  ggtitle("Resíduos da regressão linear")
```

```{r, fig.align="center"}
dados_resid <- dados %>%
  add_residuals(mod) 

dados_resid %>%
  ggplot(aes(x = resid)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = mean(dados_resid$resid), color = "green") +
  geom_vline(xintercept = median(dados_resid$resid), color = "yellow") +
  ggtitle("Histograma dos resíduos") +
  xlab("Resíduos")
```

* __Variabilidade constante__: pelo gráfico de resíduos, podemos observar que a variabilidade dos resíduos é, de certa forma, constante. __Os resíduos não são muito distantes de zero e não se comportam diferentemente ao longo do gráfico. Logo, ao meu ver, essa condição não é violada__.
* __Residuos aproximadamente normais__: por outro lado, o histograma nos mostra que a distribuição dos resíduos é concentrada à direita com cauda à esquerda. Porém, eu acredito que visualmente podemos dizer que os resíduos são aproximadamente normais, uma vez que nossa média (linha verde) é bem próxima da mediana (linha amarela) - repare que teríamos de fazer testes estatísticos pra calcular a "normalidade" da nossa curva. __Logo, a princípio, essa condição não foi violada__.

#### 3.1.1 Boostrap

Antes de efetuarmos a regressão multilinear, vamos avaliar o bootstrap no nosso modelo linear para calcularmos o intervalo de confiança do nosso modelo. Apesar desse intervalo de confiança já ter sido mostrado acima, a intenção aqui é comparar com o intervalo dado pelo bootstrap.

```{r}
set.seed(42)

mod.boot <- lm.boot(mod, R = 5000)
summary(mod.boot)
```

```{r, fig.align="center"}
mod.ci <- perc(mod.boot, p = c(0.025, 0.975)) %>% as_data_frame()
mod.ci %>% kable()
confint(mod) %>% as_data_frame() %>% kable()

mod.ci %>% 
  ggplot(aes(x = 0, ymin = bty_avg[1], ymax = bty_avg[2])) +
  geom_errorbar(width = 0.2) +
  geom_hline(yintercept = 0, color="red") +
  ggtitle("Intervalo de confiança do slope (bty_avg)") +
  labs(x = "bty_avg", y = "CI (95%)")
```

Pode-se observar que os coeficientes calculados são bem próximos (se não iguais) aos apresentados anteriormente. No entanto, podemos observar uma leve diferença nos intervalos de confiança, mas nada muito significativo.

```{r, fig.align="center"}
autoplot(mod) + theme_bw()
```

Analisando cada gráfico acima, temos:

* __Residuals vs Fitted__: esse gráfico é igual ao gráfico de resíduos já discutido anteriormente.

* __Normal Q-Q__: esse gráfico mostra se os resíduos são normalmente distribuídos. Como vimos anteriormente, nossos resíduos aparentemente são normais, mas com leve concentração à direita e cauda à esquerda.

* __Scale-Location__: esse gráfico mostra se os resíduos espalham-se igualmente ao longo da faixa de preditores. Através desse gráfico podemos checar a homocedasticidade (suposição de variância constante para observações diferentes). A homocedasticidade é boa quando temos uma reta aproximadamente horizontal com os pontos igualmente espalhados ao longo da reta. Logo, apesar de termos uma reta aproximadamente horizontal, eu acho que os pontos se espalham menos ao longo do gráfico.

* __Residuals vs Leverage__: esse gráfico ajuda olhar pontos que influenciam nossa regressão significantemente (como outliers). Esses pontos são representados nesse gráfico extremamente distantes dos demais pontos - em geral nos cantos superior/inferior direito. Portanto, nosso gráfico mostra que não há pontos que se distanciam em demasia dos demais. De fato, não há outliers nos dados, como vimos na análise descritiva. 

### 3.2 Regressão Linear Múltipla

Como o objetivo de um modelo de regressão linear é simplificar a compreensão de alguma entidade, não faz muito sentido utilizarmos as 21 variáveis para tentar predizer o score de um professor. Portanto, além da média da beleza (*bty_avg*), vou escolher algumas variáveis que acredito inicialmente que serão mais significantes que outras. Baseado na análise descritiva, eu escolheria as seguintes variáveis:

* **_age_**: de certa forma, acredito que professores mais experientes têm melhor didática.
* **_cls\_level_** e **cls_credits**: acredito que disciplinas introdutórias (ou de poucos créditos) são mais fáceis de ministrar (pelo professor) e compreender (pelos alunos). Logo, os alunos devem tender a dar notas mais altas aos professores das disciplinas que eles aprendem mais fácil.
* **pic_outfit** e **pic_color**: escolhi essas variáveis pelo desbalanceamento delas nos dados, como vimos na análise descritiva. Quero analisar como isso influencia o nosso modelo. Também quero balancear o número de variáveis não relacionadas a beleza (_age_, *cls_level* e *cls_credits*) com as relacionadas (*bty_avg* + essas duas).

Vamos, então, ver se algum palpite meu está certo:

```{r}
multi <- lm(data = dados, score ~ age + cls_level + cls_credits + pic_outfit + pic_color + bty_avg)

summary(multi)
tidy(multi, conf.int = TRUE) %>% kable()
glance(multi, conf.int = TRUE) %>% kable()
```

Pelos dados acima, agora temos que:

* a nossa nova equação da reta é:

$$
score = -0.003\cdot age + 0.019\cdot cls\_level_{upper} + 0.53\cdot cls\_credits_{one\_credit} +
\\ - 0.062\cdot pic\_outfit_{not\_formal} - 0.173\cdot pic\_color_{color} + 0.05\cdot bty\_avg
$$

Ao contrário do que eu imaginava, __a idade tem efeito negativo na regressão do score__. Ou seja, quanto maior a idade, menor o valor do _score_. Além disso, __as fotos dos professores também influenciam negativamente__. Porém, __a quantidade de créditos de uma disciplina (no caso, um crédito) foi bastante importante, apresentando o maior peso individualmente entre as variáveis (0.53)__.

* As variáveis estatísticamente significantes (que não cruzam o valor zero e com $p\mbox{-}value < 0.05$) são: $cls\_credits_{one\_credit}$, $pic\_color_{color}$ e $bty\_avg$. Vale salientar que metade das nossas variáveis foram significantes estatisticamente e apenas *bty_avg* é uma variável numérica.

* O valor de $R^2$ e $R^2\mbox{-}adjusted$ foram maiores que quando a regressão linear simples foi aplicada, o que era esperado, pois é mais fácil ajustar um modelo com mais variáveis. No entanto, esse valor ainda é baixo (0.10006337). Aproximadamente, __apenas 10% da variância da avaliação do professor é explicada pelo modelo que construimos__.

Vamos fazer agora as análises dos resíduos para cada uma das variáveis mais significantes:

```{r, fig.width=12}
residPlot <- function(data, x, y)
{
  plot <- data %>%
    ggplot(aes_string(x = x, y = y)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, color = "red")
  return(plot)
}

dados_resid <- dados %>% add_residuals(multi)

p1 <- residPlot(dados_resid, "cls_credits", "resid")
p2 <- residPlot(dados_resid, "pic_color", "resid")
p3 <- residPlot(dados_resid, "bty_avg", "resid")

multiplot(p1, p2, p3, layout = matrix(c(1,2,3,3), nrow=2, byrow = TRUE))
```

Em relação aos resíduos das variáveis categóricas, em geral eles são bem parecidos. No caso de *pic_color* e *cls_credits*, a faixa dos resíduos para um dos valores é maior que no outro. Talvez isso seja explicado pelo desbalanceamento dos dados para cada valor. Ainda, __grande parte dos resíduos se concentram entre [-1,1], ou seja, o modelo erra a nota, em geral, um ponto para mais ou para menos__. Por outro lado, eu observo um comportamento semelhante ao que tivemos na regressão linear para a variável *bty_avg*: __a variância dos resíduos aparenta ser constante ao longo do gráfico e a distribuição dos pontos é parecida, porém agora os resíduos se concentram mais no começo do gráfico__.

Também é importante notar que, no caso das variáveis categóricas, podemos observar que o modelo deu pesos altos e positivos para as variáveis com pouca variação nos resíduos ($cls\_credits_{one\_credit}$) e pesos negativos e menores para variáveis com maior variação nos resíduos ($pic\_color_{color}$). Não sei se isso é realmente um padrão, mas é ao menos um fato interessante.

Vamos analisar agora o comportamente dos resíduos:

```{r, fig.align="center"}
dados_resid %>%
  ggplot(aes(x = resid)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = mean(dados_resid$resid), color="green") +
  geom_vline(xintercept = median(dados_resid$resid), color="yellow") +
  ggtitle("Histograma dos resíduos") +
  xlab("Resíduos")
```

```{r, fig.align="center"}
autoplot(multi)
```

De acordo com o gráfico acima, temos:

* __Residuals vs Fitted__: nosso gráfico de resíduos agora mostra um comportamento diferente de quando efetuamos somente a regressão linear simples. __A nossa reta ainda é aproximadamente horizontal, porém há padrões não-lineares e os resíduos variam diferentemente ao longo do gráfico__.

* __Normal Q-Q__: esse gráfico confirma que __nossos resíduos são normalmente distribuidos__.

* __Scale-Location__: agora, temos uma reta menos horizontal que na regressão simples e com os ruídos se espalhando diferentemente ao longo do gráfico. __A condição de variabilidade constante (homocedasticidade) é quebrada nesse caso__.

* __Residuals vs Leverage__: como vimos anteriormente, esse gráfico confirma que __não há outliers nos dados que influenciem significantemente nossa regressão__.

# 4. Conclusões

* **Na regressão linear simples, nosso modelo foi estatísticamente significante** (o intervalo de confiança do slope não interceptou zero e o $p\mbox{-}value < 0.05$), **porém não foi útil para explicar os nossos dados** - uma vez que nosso $R^2 = 0.035$. Além disso, **algumas suposições de regressão foram violadas**, como a linearidade. **Os ruídos, por sua vez, não apresentam nenhum padrão aparente, foram normalmente distribuídos, boa homocedasticidade e nenhum outlier**.

* Na regressão multilinear, **a variância explicada pelo nosso modelo foi maior que no caso da regressão linear simples, porém ainda de baixa utilidade prática**. **Apenas 3 das 6 variáveis foram estatísticamente significantes**, sendo 2 categóricas e 1 numérica. **Os ruídos também se mostraram normalmente distribuídos e sem a presença de outliers, porém com variação inconstante ao longo do gráfico e padrões não-lineares**.

* Em relação a avaliação da beleza como fator significativo na avaliação docente, vimos que __a beleza teve um efeito estatísticamente significativo em ambas as regressões, mas não explicou a variância do score__. Portanto, eu afirmaria que **a beleza não apresentou um efeito significativo no _score_ dos professores tanto quando avaliada individualmente (regressão linear) quando em conjunto com outras variáveis (regressão multilinear)**.

# 5. Links Úteis

* Fluxograma de como aplicar uma regressão linear: http://www.discoveringstatistics.com/docs/linearmodels.pdf
* Visualização do modelo: http://r4ds.had.co.nz/model.html#understanding-the-model
* Explicação do autoplot: http://data.library.virginia.edu/diagnostic-plots/
* Explicação do summary: http://blog.yhat.com/posts/r-lm-summary.html
