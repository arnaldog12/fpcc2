---
title: "Lab 5 - Checkpoint 2"
author: "Arnaldo Gualberto"
date: "25/06/2017"
output: 
  html_document:
    smart: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

O objetivo checkpoint 2 do Lab 5 é avaliar se a aparência física (beleza) de um professor influência significativamente na avaliação docente dos professores pelos alunos. Além disso, vamos também analisar se outras variáveis influenciaram na nota da avalização, são elas:

* __nível do professor (_rank_)__: horista (_teaching_), assistente (_tenure track_) ou titular (_tenured_)
* __etnia (_ethnicity_)__: não minoria ou minoria
* __gênero (_gender_)__: feminino ou masculino
* __linguagem (_language_)__: inglês ou não inglês 
* __idade (_age_)__: idade do professor
* __porcentagem de alunos na turma que concluíram a avaliação (_cls_perc_eval_)__
* __número de alunos na turma que concluíram a avaliação (_cls_did_level_)__
* __número total de alunos na turma (_cls_students_)__
* __nível da disciplina (_cls_level_)__: introdutória ou avançada
* __número de professores ministrando módulos na disciplina dentro da amostra (_cls_profs_)__: único ou múltiplos
* __número de créditos na disciplina (_cls_credits_)__: um crédito ou múltiplos créditos
* __roupa do professor na foto avaliada (_pic_outfit_)__: informal ou formal
* __cor da foto avaliada (_pic_color_)__: colorida ou preto e branco

# 0. Imports and Settings

```{r, message=FALSE}
library(broom)
library(car)
library(dplyr, warn.conflicts = FALSE)
library(ggfortify)
library(GGally, warn.conflicts = FALSE)
library(ggplot2)
library(knitr)
library(modelr, warn.conflicts = FALSE)
library(readr)
library(simpleboot)

source('multiplot.R')

# Coloca todos os titulos dos gráficos centralizados
theme_update(plot.title = element_text(hjust=0.5))
```

# 1. Importação dos Dados

```{r}
dados <- read_csv("data/evals.csv")
```

Além das colunas citadas anteriormente, também podemos ver outras colunas. A coluna _score_ representa a média da avaliação do docente e é essa variável que tentaremos predizer. As colunas _bty\_\*_ representam a avaliação da beleza do professor feita por seis alunos de diferentes sexos e períodos (iniciante e avançado).

# 2. Análise Descritiva

Vamos começar nossa análise descritiva pelo sumário dos dados:

```{r}
dados %>% summary() %>% kable()
```

O sumário dos dados nos mostra que:

* Ao todo, temos 463 professores avaliados e 21 variáveis, sendo 12 númericas e 9 categóricas;
* Na média e na mediana, os professores tem boas avaliações em geral (> 4.0);
* Uma porcentagem razoável de estudantes respondia as pesquisas (aproximadamente 75%), sendo mais de 36 estudantes na média;
* A média e mediana das avaliações da beleza foi bem baixa na minha opinião entre os estudantes de todos os níveis e na avaliação média.

Agora, vamos analisar a distribuição de cada uma das variáveis. Vou começar pelas variáveis numéricas:

```{r, fig.width=12, fig.height=8}
barPlot <- function(data, x)
{
  plot <- data %>%
    ggplot(aes_string(x = x)) +
    geom_bar()
  return(plot)
}

p1 <- barPlot(dados, "score")
p2 <- barPlot(dados, "bty_avg")
p3 <- barPlot(dados, "age")
p4 <- barPlot(dados, "cls_perc_eval")
p5 <- barPlot(dados, "cls_did_eval")
p6 <- barPlot(dados, "cls_students")

multiplot(p1, p2, p3, p4, p5, p6, cols = 1)
```

Podemos observar que as variáveis *cls_did_eval* e *cls_students* apresentam uma distribuição concentrada à esquerda com cauda longa à direita, enquanto o *score* tem uma distribuição oposta. Além disso, *bty_avg* e *age* apresentam distribuições multimodais.

Vamos ver como se comportam as variáveis categóricas:

```{r, fig.width=12}
p1 <- barPlot(dados, "rank")
p2 <- barPlot(dados, "ethnicity")
p3 <- barPlot(dados, "gender")
p4 <- barPlot(dados, "language")
p5 <- barPlot(dados, "cls_level")
p6 <- barPlot(dados, "cls_profs")
p7 <- barPlot(dados, "cls_credits")
p8 <- barPlot(dados, "pic_outfit")
p9 <- barPlot(dados, "pic_color")

multiplot(p1, p2, p3, p4, p5, p6, p7, p8, p9, cols = 3)
```

Os gráficos acima nos mostram o desbalanceamento dos dados, em especial sobre as variáveis *language*, *cls_credit*, *ethnicity*, *pic_outfit*, e *pic_color*, que estão presentes em menos de 100 vezes nos dados.

Vamos agora analisar a dispersão das variáveis em relação ao score. Novamente, vou separar essa análise para as variáveis númericas e categóricas. No caso das variáveis númericas, também calcularei o coeficiente de correlação.

```{r, fig.width=12}
pointPlot <- function(data, x, y)
{
  plot <- data %>%
    ggplot(aes_string(x = x, y = y)) +
    geom_point(alpha = 0.3) +
    ylim(c(1,5))
  return(plot)
}

p1 <- pointPlot(dados, "age", "score")
p2 <- pointPlot(dados, "cls_perc_eval", "score")
p3 <- pointPlot(dados, "cls_did_eval", "score")
p4 <- pointPlot(dados, "cls_students", "score")

multiplot(p1, p2, p3, p4, cols = 2)

cor(dados$age, dados$score)
cor(dados$cls_perc_eval, dados$score)
cor(dados$cls_did_eval, dados$score)
cor(dados$cls_students, dados$score)
```

É possível observar que não há uma linearidade aparente entre as variáveis mostradas e o _score_. Além disso, o maior coeficiente de correlação (0.18) ocorreu para a variável *cls_perc_eval*. Mesmo assim, esse valor representa uma correlação positiva, porém fraca.

```{r, fig.width=12}
p1 <- pointPlot(dados, "rank", "score")
p2 <- pointPlot(dados, "ethnicity", "score")
p3 <- pointPlot(dados, "gender", "score")
p4 <- pointPlot(dados, "language", "score")
p5 <- pointPlot(dados, "cls_level", "score")
p6 <- pointPlot(dados, "cls_profs", "score")
p7 <- pointPlot(dados, "cls_credits", "score")
p8 <- pointPlot(dados, "pic_outfit", "score")
p9 <- pointPlot(dados, "pic_color", "score")

multiplot(p1, p2, p3, p4, p5, p6, p7, p8, p9, cols = 3)
```

A relação entre as variáveis categóricas e o score não nos diz muita coisa, já que a faixa de scores é basicamente a mesma para todas as variáveis. Porém, um fato interessante que pode ser observado é a tendência de scores mais altos para disciplinas de um crédito.

Por fim, vamos terminar nossa análise descritiva observando a (cor)relação entre as variáveis de interesse para a regressão linear simples: *bty_avg* e _score_:

```{r, fig.align="center"}
dados %>%
  ggplot(aes(x = bty_avg, y = score)) +
  geom_point(alpha = 0.5) +
  ggtitle("Scatterplot do score pela média da beleza (bty_avg)")

cor(dados$score, dados$bty_avg, method = "pearson")
```

Pelo gráfico acima, já podemos avaliar algumas das condições para regressão linear:

* __Linearidade__: o coeficiente de correlação nos mostra que __há pouca linearidade entre o _score_ do professor e a média da avaliação da beleza do professor. Logo, essa condição já está violada.__
* __Outliers__: por outro lado, não há nenhum ponto amplamente afastado dos demais, representando um outlier.  

# 3. Regressão Linear

### 3.1 Regressão linear simples

Vamos começar a criando o modelo linear simples para tentar predizer o score da avaliação do professor pela média da beleza:

```{r, fig.align="center"}
mod <- lm(data = dados, score ~ bty_avg)

summary(mod)
tidy(mod, conf.int = TRUE) %>% kable()
glance(mod, conf.int = TRUE) %>% kable()

predictions <- predict(mod, dados, interval = "predict") %>% as.data.frame()

dados %>%
  add_predictions(mod) %>%
  ggplot(aes(x = bty_avg, y = score)) +
  geom_point(alpha = 0.5) +
  geom_line(aes(y = pred), colour = "red") +
  geom_line(aes(y = predictions$lwr), colour = "blue") +
  geom_line(aes(y = predictions$upr), colour = "blue") +
  ggtitle("Regressão Linear do score por bty_avg")
```

O gráfico e os dados acima já nos mostram informações interessantes:

* A equação da nossa reta é dada por: 

$$score = 3.88 + 0.06 \cdot bty\_avg$$. 

Isso significa que __para cada unidade que aumentamos *bty_avg*, o _score_ do professor aumenta apenas 0.06__.

* __Há uma relação linear estatística significativa entre a avaliação do professor e sua beleza__, uma vez que o intervalo de confiança do slope (*bty_avg*) não intercepta o valor zero e seu $p\mbox{-}value < 0.05$

* __Como ambos $R^2$ e $R^2\mbox{-}adjusted$ foram baixos (0.03502226 e 0.03292903, respectivamente), a relação linear entre a beleza e o score é muito fraca__ (como confirmado pelo coeficiente de correlação). Aproximadamente, __apenas 3,5% da variância na avaliação do professor é explicada pela média da avaliação da beleza__.

Temos agora que analisar o gráfico de resíduos e seu histograma para verificarmos as demais condições:

```{r, fig.align="center"}
dados %>%
  add_residuals(mod) %>%
  ggplot(aes(x = bty_avg, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_hline(yintercept = 0, colour = "blue") +
  ggtitle("Resíduos da regressão linear")
```

```{r, fig.align="center"}
dados_resid <- dados %>%
  add_residuals(mod) 

dados_resid %>%
  ggplot(aes(x = resid)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = mean(dados_resid$resid), color = "green") +
  geom_vline(xintercept = median(dados_resid$resid), color = "yellow") +
  ggtitle("Histograma dos resíduos") +
  xlab("Resíduos")
```

* __Variabilidade constante__: pelo gráfico de resíduos, podemos observar que a variabilidade dos resíduos é, de certa forma, constante. __Os resíduos não são muito distantes de zero e não se comportam diferentemente ao longo do gráfico. Logo, ao meu ver, essa condição não é violada__.
* __Residuos aproximadamente normais__: por outro lado, o histograma nos mostra que a distribuição dos resíduos é concentrada à direita com cauda à esquerda. Porém, eu acredito que visualmente podemos dizer que os resíduos são aproximadamente normais, uma vez que nossa média (linha verde) é bem próxima da mediana (linha amarela) - repare que teríamos de fazer testes estatísticos pra calcular a "normalidade" da nossa curva. __Logo, a princípio, essa condição não foi violada__.

#### 3.1.1 Boostrap

Antes de efetuarmos a regressão multilinear, vamos avaliar o bootstrap no nosso modelo linear para calcularmos o intervalo de confiança do nosso modelo. Apesar desse intervalo de confiança já ter sido mostrado acima, a intenção aqui é comparar com o intervalo dado pelo bootstrap.

```{r}
set.seed(42)

mod.boot <- lm.boot(mod, R = 5000)
summary(mod.boot)
```

```{r, fig.align="center"}
mod.ci <- perc(mod.boot, p = c(0.025, 0.975)) %>% as_data_frame()
mod.ci %>% kable()
confint(mod) %>% as_data_frame() %>% kable()

mod.ci %>% 
  ggplot(aes(x = 0, ymin = bty_avg[1], ymax = bty_avg[2])) +
  geom_errorbar(width = 0.2) +
  geom_hline(yintercept = 0, color="red") +
  ggtitle("Intervalo de confiança do slope (bty_avg)") +
  labs(x = "bty_avg", y = "CI (95%)")
```

Pode-se observar que os coeficientes calculados são bem próximos (se não iguais) aos apresentados anteriormente. No entanto, podemos observar uma leve diferença nos intervalos de confiança, mas nada muito significativo.

```{r, fig.align="center"}
autoplot(mod) + theme_bw()
```

Analisando cada gráfico acima, temos:

* __Residuals vs Fitted__: esse gráfico é igual ao gráfico de resíduos já discutido anteriormente.

* __Normal Q-Q__: esse gráfico mostra se os resíduos são normalmente distribuídos. Como vimos anteriormente, nossos resíduos são concentrados à direita com cauda à esquerda.

* __Scale-Location__: esse gráfico mostra se os resíduos espalham-se igualmente ao longo da faixa de preditores. Através desse gráfico podemos checar a homocedasticidade (suposição de variância constante para observações diferentes). A homocedasticidade é boa quando temos uma reta aproximadamente horizontal com os pontos igualmente espalhados ao longo da reta. Logo, apesar de termos uma reta aproximadamente horizonta eu acho que os pontos se espalham menos ao longo do gráfico.

* __Residuals vs Leverage__: esse gráfico ajuda olhar pontos que influenciam nossa regressão significantemente (como outliers). Esses pontos são representados nesse gráfico extremamente distantes dos demais pontos - em geral nos cantos superior/inferior direito. Portanto, nosso gráfico mostra que não há pontos que se distanciam em demasia aos demais. De fato, não há outliers nos dados, como vimos na análise descritiva. 

### 3.2 Regressão Linear Múltipla

Antes de ajustar o modelo da regressão para múltiplas variáveis, eu acredito que algumas variáveis serão mais importantes que outras, são elas: 

* **_age_**: de certa forma, professores mais experientes tem melhor didática.
* **_rank_**: idem.
* **_cls\_level_**: acredito que disciplinas introdutórias são mais fáceis de ministrar (pelo professor) e compreender (pelo aluno). Logo, os alunos devem tender a dar notas mais altas aos professores das disciplinas que eles aprendem mais fácil.

Vamos, então, ver se algum palpite meu está certo:

```{r}
multi <- lm(data = dados, score ~ . )

summary(multi)
tidy(multi, conf.int = TRUE) %>% kable()
glance(multi, conf.int = TRUE) %>% kable()
```

Pelos dados acima, agora temos que:

* **as variáveis _bty\_\*_ representam as variáveis mais importantes agora, pois apresentam os maiores coeficientes de _estimate_**. É interessante notar, no entanto, que a soma das avaliações da beleza é bem próxima do negativo da média (*bty_avg*), ou seja, de certa forma elas se anulam. **Além disso, todas as variáveis de beleza (_bty\_\*_) não são estatísticamente significantes, já que o intervalo de confiança cruza o valor zero**.
* As variáveis estatísticamente significantes (que não cruzam o valor zero e com $p\mbox{-}value < 0.05$) são: _ranktenure track_, _gendermale_, _languagenon-english_, _age_, *cls_creditsone credit*, *pic_colorcolor*. Vale salientar que praticamente todas as variáveis estatísticamente significantes são categóricas, com exceção da idade (_age_).
* O valor de $R^2$ e $R^2\mbox{-}adjusted$ foram maiores que quando a regressão linear simples foi aplicada, o que era esperado, pois é mais fácil ajustar um modelo com mais variáveis. No entanto, esse valor ainda é baixo. Aproximadamente, __apenas 20% da variância da avaliação do professor é explicada pelo modelo que construimos__.

Vamos fazer agora as análises dos resíduos para cada uma das variáveis mais significantes:

```{r, fig.width=12}
residPlot <- function(data, x, y)
{
  plot <- data %>%
    ggplot(aes_string(x = x, y = y)) +
  geom_point(alpha = 0.3) +
  geom_hline(yintercept = 0, color = "red")
  return(plot)
}

dados_resid <- dados %>% add_residuals(multi)

p1 <- residPlot(dados_resid, "rank", "resid")
p2 <- residPlot(dados_resid, "gender", "resid")
p3 <- residPlot(dados_resid, "language", "resid")
p4 <- residPlot(dados_resid, "age", "resid")
p5 <- residPlot(dados_resid, "cls_credits", "resid")
p6 <- residPlot(dados_resid, "pic_color", "resid")

multiplot(p1, p2, p3, p4, p5, p6, cols = 3)
```

Em relação aos resíduos das variáveis categóricas, em geral eles são bem parecidos. Em alguns casos, como _language_ e *cls_credits*, a faixa dos resíduos para um dos valores é maior que no outro. Talvez isso seja explicado pelo desbalanceamento dos dados para cada valor. Ainda, grande parte dos resíduos se concentram entre [-1,1], ou seja, o modelo erra a nota um ponto para mais ou para menos. Por outro lado, eu observo um comportamento semelhante ao que tivemos na regressão linear para a variável _age_: a variância dos resíduos aparenta ser constante ao longo do gráfico e a distribuição dos pontos é parecida.

```{r}
dados_resid %>%
  ggplot(aes(x = resid)) +
  geom_histogram(bins = 30) +
  geom_vline(xintercept = mean(dados_resid$resid), color="green") +
  geom_vline(xintercept = median(dados_resid$resid), color="yellow") +
  ggtitle("Histograma dos resíduos") +
  xlab("Resíduos")
```


```{r, fig.align="center"}
autoplot(multi)
```

De acordo com o gráfico acima, temos:

* __Residuals vs Fitted__: nosso gráfico de resíduos agora mostra um comportamento semelhante de quando efetuamos somente a regressão linear simples. A nossa reta ainda é aproximadamente horizontal e não há padrões não-lineares, apesar dos resíduos variarem mais em certa faixa de valores.

* __Normal Q-Q__: esse gráfico confirma que nossos resíduos são normalmente distribuidos.

* __Scale-Location__: novamente, temos uma reta aproximadamente horizontal com os ruídos se espalhando mais e menos ao longo do gráfico.

* __Residuals vs Leverage__: como vimos anteriormente, esse gráfico confirma que não há outliers nos dados que influeciem significantemente nossa regressão.

# 4. Conclusões

* Na regressão linear simples, nosso modelo foi estatísticamente significante (o intervalo de confiança do slope não interceptou zero e o $p\mbox{-}value < 0.05$), porém não foi útil para explicar os nossos dados - uma vez que nosso $R^2 = 0.035$. Além disso, algumas suposições de regressão foram violadas, como a linearidade. Os ruídos, por sua vez, não apresentam nenhum padrão aparente, foram normalmente distribuídos, boa homocedasticidade e nenhum outlier.

* Na regressão multilinear, a variância explicada pelo nosso modelo foi maior que no caso da regressão linear simples, porém ainda de baixa utilidade prática. Apenas 6 variáveis foram estatísticamente significantes, sendo 5 categóricas e 1 numérica. Os ruídos se comportaram de maneira similar, porém com variação inconstante ao longo do gráfico.

# 5. Links Úteis

* http://rpubs.com/sinhrks/plot_lm
