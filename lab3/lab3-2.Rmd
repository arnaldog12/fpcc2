---
title: "Lab 3 - Checkpoint 2"
author: "Arnaldo Gualberto"
date: "27/04/2017"
output: 
  html_document:
    smart: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

O objetivo do Lab 3 é tentar agrupar dados de filmes utilizando algoritmos de agrupamento. Para essa análise, eu utilizei essa [base de dados](https://www.kaggle.com/deepmatrix/imdb-5000-movie-dataset). Mais detalhes sobre os dados podem ser encontrados na própria página.

# 0. Imports and Settings
```{r, message=FALSE}
library(cluster)
library(dplyr, warn.conflicts=FALSE)
library(GGally)
library(ggplot2)
library(knitr)
library(readr)
library(tibble)
library(tidyverse, warn.conflicts = FALSE)
source('multiplot.R')
```

# 1. Análise Descritiva

Primeiramente, vou carregar os dados que vou utilizar para análise:

```{r, message=FALSE}
dados <- read_csv('data/movie_metadata.csv')
glimpse(dados)
```

De acordo com a saída do código R, podemos ver que existem alguns dados faltando. Como são apenas 4, resolvi descartá-los. Também vou analisar somentes os dados dos filmes dos Estados Unidos. Por fim, também vou descartar os filmes com título duplicado e selecionar as colunas que me interessam, são elas:

- __gross__: bilheteria arrecadada pelo filme;
- __budget__: orçamento gasto para produção do filme;
- __imdb_score__: avaliação média dos usuários do IMBD;
- __duration__: duração do filme (em minutos);
- __movie_facebook_likes__: quantidade de likes do filme na página do facebook;
- __actor_1_facebook_likes__: quantidade de likes do ator no facebook;

Além dessas colunas, também resolvi extrair outras que podem ser interessantes na análise final do agrupamento, são elas:

- __movie_title__: representa o título do filme;
- __actor_1_name__: nome do ator principal;

```{r}
dados_usa = dados %>%
  filter(!duplicated(dados$movie_title)) %>%
  filter(country == 'USA') %>%
  filter(complete.cases(.)) %>%
  select(filme = movie_title, ator = actor_1_name, bilheteria = gross, orcamento = budget, duracao = duration, avaliacao = imdb_score, likes_filme = movie_facebook_likes, likes_ator = actor_1_facebook_likes)

head(dados_usa) %>% kable()
```

Ao todo, após as filtragens, temos dados sobre __2097 filmes dos Estados Unidos__.

Vou iniciar a análise descritiva analisando a sumarização dos dados:

```{r}
dados_usa %>%
  select(-filme, -ator) %>%
  summary() %>% 
  kable()
```

Pode-se perceber que _avaliação_ e _duração_ do filme são as variáveis com menor range, ou seja, que menos variam em comparação com as outras variáveis. _Bilheteria_ e _orçamento_ apresentam enormes variações, com valores máximo e mínimo bem distante das média e mediana. Logo, mais para frente, deveremos tratar esses valores para que o agrupamento não seja totalmente influenciado por essas variáveis.

Também quero saber o desvio-padrão de cada variável utilizada:

```{r}
dados_usa %>% summarise(sd(bilheteria), sd(orcamento), sd(avaliacao), sd(duracao), sd(likes_ator), sd(likes_filme)) %>%
  kable()
```

É importante saber o desvio-padrão de cada variável quando eu for normalizar os valores aplicando a _padronização_. Ex.: sabendo que a variável _bilheteria_ apresenta $\mu \approx$ 58 milhões e $\sigma \approx$ 72 milhões, filmes que arrecadaram 200 milhões de dólares em bilheteria estão a aproximadamente dois desvios-padrões da média ($\approx \mu + 2\sigma$).

A título de curiosidade, quero saber quais são os filmes cujo cada variável que eu escolhi para análise apresenta seu valor máximo:

```{r}
dados_usa %>%
  filter(likes_ator == max(likes_ator)) %>%
  kable()
```

```{r}
dados_usa %>%
  filter(likes_filme == max(likes_filme)) %>%
  kable()
```

```{r}
dados_usa %>%
  filter(bilheteria == max(bilheteria)) %>%
  kable()
```

```{r}
dados_usa %>%
  filter(orcamento == max(orcamento)) %>%
  kable()
```

```{r}
dados_usa %>%
  filter(avaliacao == max(avaliacao)) %>%
  kable()
```

```{r}
dados_usa %>%
  filter(duracao == max(duracao)) %>%
  kable()
```

Podemos perceber que __Avatar__ é o filme que mais arrecadou bilheteria nos EUA, enquanto __Piratas do Caribe: o fim do mundo__ foi o filme que mais gastou-se para ser produzido. Além disso, o filme mais bem avaliado pelos usuários do IMDB é __The Shawshank Redemption__ (em português, _Um sonho de liberdade_). Pelos dados do facebook utilizados, o filme __Interstellar__ e a atriz __Darcy Donavam__ são o filme e a atriz com mais curtidas, respectivamente. Finalmente, __Blood In, Blood Out__ é o longa-metragem mais longo dos EUA, com aproximadamente 5h30min de duração.

Quero analisar agora a distribuição de cada variável individualmente e em pares. Para isso, vou utilzar _ggpairs_ do módulo _GGally_:

```{r, fig.width=12, fig.height=6}
dados_usa %>%
  select(-filme, -ator) %>%
  GGally::ggpairs()
```

Pelo gráfico acima, ao analisar as distribuições de cada variável (diagona principal), podemos perceber que quase todas apresentam uma concentração à esquerda com cauda longa à direita, exceto a variável _avaliação_.

Também podemos observar que praticamente todas as variáveis utilizadas apresentam pouca correlação entre si. De fato, apenas _orçamento_ e _bilheteria_, apresentam um correlação mais forte (0.637). Isso indica, de certa forma, que quanto mais se gasta para produzir um filme, maior é o retorno na bilheteria.

Para finalizar minha análise descritiva, quero observar a distribuição dos 2097 filmes de acordo com cada variável:

```{r, fig.width=12}
plot_bil <- dados_usa %>%
  ggplot(aes(x = 0, y = bilheteria)) +
  geom_point(position = position_jitter(width=0.3))

plot_orc <- dados_usa %>%
  ggplot(aes(x = 0, y = orcamento)) +
  geom_point(position = position_jitter(width=0.3))

plot_dur <- dados_usa %>%
  ggplot(aes(x = 0, y = duracao)) +
  geom_point(position = position_jitter(width=0.3))

plot_ava <- dados_usa %>%
  ggplot(aes(x = 0, y = avaliacao)) +
  geom_point(position = position_jitter(width=0.3))

plot_lf <- dados_usa %>%
  ggplot(aes(x = 0, y = likes_filme)) +
  geom_point(position = position_jitter(width=0.3))

plot_la <- dados_usa %>%
  ggplot(aes(x = 0, y = likes_ator)) +
  geom_point(position = position_jitter(width=0.3))

multiplot(plot_bil, plot_orc, plot_dur, plot_ava, plot_lf, plot_la,  cols = 2)
```

Os gráficos acima apresentam pontos interessantes:

- Os dados de _bilheteria_, _orçamento_, *likes_ator* e *likes_filme* se concentram, em sua maioria, na base do gráfico;
- Em geral, a média de _duração_ dos filmes é aproximadamente 100 minutos (como verificado na sumarização dos dados);
- Os dados de _avaliação_ são visualmente os mais dispersos, variando disformemente por todo o gráfico, mas com uma concentração maior entre 5,0 e 7,5.

Pela distribuição dos dados acima, eu arriscaria dizer que existem de 2 a, no máximo, 4 grupos de filmes diferentes. Vamos verificar isso na próxima seção.

# 2. Clusterização

Agora vou dar início ao agrupamento (clusterização) dos dados. Antes de mais nada, vou efetuar a __padronização__ dos dados:

```{r}
filmes = dados_usa %>%
  select(-filme, -ator) %>%
  mutate(bilheteria = scale(bilheteria),
           orcamento = scale(orcamento),
           duracao = scale(duracao),
           likes_filme = scale(likes_filme),
           likes_ator = scale(likes_ator),
           avaliacao = scale(avaliacao))
```

## 2.1 Clusterização Hierárquica {#hclust}

O primeiro algoritmo de clusterização que vou utilizar é a __clusterização hierárquica__. Empiricamente, escolhi o método __ward.D__ e a __distância de Manhattan__. Além disso, defini clusterizar os dados em __3 grupos diferentes__, pois vi que essa combinação de parâmetros geraram grupos melhores. 

__Observação__: testei diversas combinações de métodos de distância e de clusterização. Além disso, também normalizeis os dados de maneiras diferentes (padronização e normalização entre [0-1]). Os valores escolhidos foram os que geraram os melhores grupos, ao meu ver. Em muitas combinações houveram grupos com poucos filmes, o que não achei interessante.

```{r, fig.width=12}
agrupamento_hs <- filmes %>%
  dist(method = "manhattan") %>%
  hclust(method = "ward.D")

# Retomando os valores do título do filme e ator_principal para que apareçam na tabela atribuições
filmes <- dados_usa %>%
  mutate(bilheteria = scale(bilheteria),
           orcamento = scale(orcamento),
           duracao = scale(duracao),
           likes_filme = scale(likes_filme),
           likes_ator = scale(likes_ator),
           avaliacao = scale(avaliacao))

atribuicoes <- tibble(k = 1:3) %>%
  group_by(k) %>%
  do(cbind(filmes, grupo = cutree(agrupamento_hs, .$k)))

atribuicoes_long = atribuicoes %>%
  select(-filme, -ator) %>%
  gather(key = "variavel", value = "valor", -k, -grupo)

atribuicoes_long %>%
  ggplot(aes(x = variavel, y = valor, group = grupo, colour = grupo)) +
  geom_point(alpha = .4, position = position_dodge(width = .5)) +
  facet_grid(paste(k, " grupos" )~ .) +
  labs(x = "", y = "z-score") +
  theme(legend.position = "none")
```

Também podemos visualizar o gráfico acima com coordenadas paralelas. É importante notar, entretanto, que as variáveis (eixo x) estão distribuidas diferentemente nos gráficos com pontos e coordenadas paralelas. 

```{r, fig.width=12}
atribuicoes %>%
  ggparcoord(columns = c(4:9), groupColumn="grupo") +
  facet_grid(paste(k, " grupos" )~ .) +
  labs(x = "", y = "z-score") +
  theme(legend.position = "none")
```

Separando os 3 grupos em gráficos diferentes, temos:

```{r, fig.width=12}
atribuicoes %>%
  filter(k == 3) %>%
  ggparcoord(columns = c(4:9), groupColumn="grupo") +
  facet_grid(paste("Grupo ", grupo)~ .) +
  labs(x = "", y = "z-score") +
  theme(legend.position = "none")
```

Pelos gráficos, acredito que podemos diferenciar os 3 grupos da seguinte forma:

__Grupo 1__: _Marketeiros_  
Filmes de altíssima bilheteria, alto orçamento, longa duração, boa avaliação em geral, muitas curtidas no facebook e atores renomados.

__Grupo 2__: _Fracassados_  
Filmes com maior orçamento que bilheteria, longa duração, avaliação ruim, poucas curtidas no facebook e atores renomados ou pouco conhecidos.

__Grupo 3__: _Para todos os gostos_   
Filmes de boa bilheteria e orçamento, curta-e-longa duração, boa avaliação, muitas curtidas no facebook e atores renomados.

Vamos agora ver alguns dos filmes de cada grupo:

```{r}
filmes_hclust <- atribuicoes %>%
  filter(k == 3) %>%
  left_join(dados_usa, by=c("filme")) %>%
  select(k, filme, ator.y, bilheteria.y, orcamento.y, duracao.y, likes_filme.y, likes_ator.y, avaliacao.y, grupo)

filmes_hclust %>%
  filter(grupo == 1) %>%
  top_n(10, bilheteria.y) %>%
  kable()
```

```{r}
filmes_hclust %>%
  filter(grupo == 2) %>%
  head(10) %>%
  kable()
```

```{r}
filmes_hclust %>%
  filter(grupo == 3) %>%
  top_n(10, duracao.y) %>%
  kable()
```

Ao meu ver, os filmes apresentados se encaixam bem nos grupos descritos.

# 2.2 K-Means

Vamos agora utilizar o algoritmo __K-Means__. Resolvi também utilizar 3 grupos para poder comparar os dois algoritmos.

```{r, fig.width=12}
filmes <- dados_usa

atribuicoes <- tibble(k = 1:3) %>%
  group_by(k) %>%
  do(cbind(filmes, grupo = cutree(agrupamento_hs, .$k)))

km <- filmes %>%
  select(-filme, -ator) %>%
  mutate(bilheteria = scale(bilheteria),
           orcamento = scale(orcamento),
           duracao = scale(duracao),
           likes_filme = scale(likes_filme),
           likes_ator = scale(likes_ator),
           avaliacao = scale(avaliacao)) %>%
  kmeans(centers = 3, nstart=20)

filmes$kmcluster = km$cluster

filmes %>%
  ggparcoord(columns = c(3:8), groupColumn="kmcluster") +
  facet_grid(paste("Grupo ", kmcluster) ~ .) +
  labs(x = "", y = "z-score") +
  theme(legend.position = "none")
```

De acordo com o gráfico, podemos dizer que os 3 grupos se caracterizam da seguinte forma:

__Grupo 1__: _Para todos os gostos_   
Filmes de boa bilheteria e orçamento, __longa duração__, boa avaliação, muitas curtidas no facebook e atores renomados.

__Grupo 2__: _Marketeiros_  
Filmes de altíssima bilheteria, alto orçamento, longa duração, boa avaliação em geral, muitas curtidas no facebook e atores renomados.

__Grupo 3__: _Fracassados_  
Filmes com maior orçamento que bilheteria, __curta-e-longa duração__, avaliação ruim, poucas curtidas no facebook e atores renomados ou pouco conhecidos.

***
__Observação 1__: as variáveis destacadas em negrito representam as mudanças em relação ao grupo de mesmo nome dado pelo algoritmo de clusterização hierárquica (ver [seção 2.1](#hclust)).

__Observação 2__: a ordem dos grupos citados acima pode ser diferentes dos gráficos, pois todas vez que o código R é executado a clusterização pode gerar resultados diferentes.

***

Vamos agora observar alguns filmes de cada um dos grupos:

```{r}
filmes %>%
  filter(kmcluster == 1) %>%
  top_n(10, avaliacao) %>%
  kable()
```

```{r}
filmes %>%
  filter(kmcluster == 2) %>%
  top_n(10, bilheteria) %>%
  kable()
```

```{r}
filmes %>%
  filter(kmcluster == 3) %>%
  head(10) %>%
  kable()
```

# 3. Conclusões

Este relatório realizou o agrupamento de dados de filmes em 3 grupos utilizando métodos de agrupamento diferentes: __clusterização hierárquica__ e __K-Means__.

De acordo com os resultados, podemos concluir que:

* As variáveis escolhidas apresentam distribuições semelhantes, mas com faixa de valores bem diferentes;
* A escolha do método de distância e da estratégia de padronização dos dados é crucial para o resultado da clusterização, influenciando significativamente na categorização dos dados em grupos;
* Em ambos os métodos de agrupamento utilizados, os grupos apresentam semelhanças entre si, não sendo tão distintos uns dos outros. 
* Não foi possível gerar gráficos de silhueta para comparar a atribuição dos filmes nos grupos, pois a quantidade de dados analisados (2097 filmes) torna muito difícil a visualização do gráfico de silhueta. Por esse motivo, resolvi não mostrar esse gráfico.
* Houve um grupo parecido nos dois métodos: _Marketeiros_.

